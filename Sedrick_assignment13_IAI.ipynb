{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7p3I2beLuSkGzk9W+Pe+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sedkameni/IntroAI_Willis/blob/main/Sedrick_assignment13_IAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview of this notebook\n",
        "This notebook provides a comprehensive implementation covering all assignment requirements:\n",
        "1. Dataset preparation (Project Gutenberg)\n",
        "2. GPT architecture explanation and comparison\n",
        "3. Model implementation (RNN-based for practical training)\n",
        "4. Application demonstration\n",
        "5. Visualizations and analysis\n",
        "6. Ethical considerations discussion\n"
      ],
      "metadata": {
        "id": "t1QrPwvqqegJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 1: INTRODUCTION TO GENERATIVE AI\n",
        "##GENERATIVE AI OVERVIEW:\n",
        "\n",
        "Generative AI refers to artificial intelligence systems capable of creating new\n",
        "content (text, images, audio, code) based on patterns learned from training data.\n",
        "\n",
        "##KEY CHARACTERISTICS:\n",
        "- Creates novel outputs rather than classifying inputs\n",
        "- Learns probabilistic distributions of data\n",
        "- Can generate coherent, contextually relevant content\n",
        "\n",
        "##SIGNIFICANCE:\n",
        "- Democratizes content creation\n",
        "- Assists in creative tasks (writing, design, music)\n",
        "- Enables automation of complex tasks\n",
        "- Drives innovation in human-AI collaboration\n",
        "\n",
        "## TYPES:\n",
        "1. Language Models (GPT, BERT)\n",
        "2. Image Generators (DALL-E, Stable Diffusion)\n",
        "3. Audio Synthesis (WaveNet, MusicLM)\n",
        "4. Code Generation (Codex, AlphaCode)\n",
        "\n"
      ],
      "metadata": {
        "id": "_M18D8qsq2Ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 2: GPT ARCHITECTURE EXPLANATION\n",
        "\n",
        "\n",
        "GENERATIVE PRE-TRAINED TRANSFORMER (GPT) ARCHITECTURE:\n",
        "\n",
        "1. TRANSFORMER FOUNDATION:\n",
        "   - Based on \"Attention is All You Need\" (Vaswani et al., 2017)\n",
        "   - Uses self-attention mechanism instead of recurrence\n",
        "   - Processes entire sequences in parallel\n",
        "\n",
        "2. KEY COMPONENTS:\n",
        "\n",
        "   a) TOKENIZATION:\n",
        "      - Breaks text into subword units (BPE, WordPiece)\n",
        "      - Vocabulary size: typically 50,000-100,000 tokens\n",
        "      - Handles rare words via subword splitting\n",
        "   \n",
        "   b) EMBEDDING LAYER:\n",
        "      - Converts tokens to dense vectors\n",
        "      - Combines token embeddings + positional encodings\n",
        "      - Positional encodings: allow model to understand sequence order\n",
        "   \n",
        "   c) SELF-ATTENTION MECHANISM:\n",
        "      - Query (Q), Key (K), Value (V) matrices\n",
        "      - Attention(Q,K,V) = softmax(QK^T/√d_k)V\n",
        "      - Allows each token to \"attend\" to all other tokens\n",
        "      - Multi-head attention: multiple parallel attention operations\n",
        "   \n",
        "   d) FEED-FORWARD NETWORKS:\n",
        "      - Applied to each position independently\n",
        "      - Typically: Linear -> ReLU -> Linear\n",
        "      - Dimension expansion: 4x hidden size\n",
        "   \n",
        "   e) LAYER NORMALIZATION & RESIDUAL CONNECTIONS:\n",
        "      - Stabilizes training\n",
        "      - Enables deep architectures (GPT-3: 96 layers)\n",
        "   \n",
        "   f) OUTPUT LAYER:\n",
        "      - Linear projection to vocabulary size\n",
        "      - Softmax to produce probability distribution\n",
        "\n",
        "3. TRAINING PROCESS:\n",
        "   - Pre-training: Next-token prediction on massive corpora\n",
        "   - Objective: maximize P(token_i | token_1, ..., token_{i-1})\n",
        "   - Self-supervised learning (no labels needed)\n",
        "   - Optional: Fine-tuning on specific tasks\n",
        "\n",
        "4. TEXT GENERATION:\n",
        "   - Autoregressive: generates one token at a time\n",
        "   - Uses previous tokens as context\n",
        "   - Sampling strategies: greedy, top-k, top-p (nucleus), temperature\n",
        "\n",
        "5. GPT vs RNN COMPARISON:\n",
        "   \n",
        "   RNN (Our Implementation):\n",
        "   + Simpler architecture, faster to train\n",
        "   + Good for learning local patterns\n",
        "   - Sequential processing (slow)\n",
        "   - Vanishing gradient issues\n",
        "   - Limited context window\n",
        "   \n",
        "   GPT (Transformer):\n",
        "   + Parallel processing (faster inference)\n",
        "   + Long-range dependencies via attention\n",
        "   + Scalable to billions of parameters\n",
        "   - Requires more compute resources\n",
        "   - Quadratic complexity in sequence length\n",
        "\n",
        "NOTE: This notebook implements an RNN-based model for practical training,\n",
        "but the concepts apply to GPT-style transformers at scale.\n"
      ],
      "metadata": {
        "id": "j8JXyiqprPpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" IMPORT USEFUL LIBRQRIES\")\n",
        "print(\"=\"*80)\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEk2bMi7re4N",
        "outputId": "91448d69-4b5a-44c6-ace8-70e30a2bfb55"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " IMPORT USEFUL LIBRQRIES\n",
            "================================================================================\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68f0363c"
      },
      "source": [
        "Next, you might need to install a LaTeX distribution if you don't have one, as `nbconvert` uses it for PDF generation. In Colab, you can often install `texlive-xetex`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbb97256"
      },
      "source": [
        "Now, you can convert your notebook to PDF. Replace `/Sedrick_assignment13_IAI.ipynb` with the actual path to your notebook file if it's different. The output PDF will be saved in the same directory as your notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 3: DATASET PREPARATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 3: DATASET PREPARATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create data directory\n",
        "data_dir = Path('/mnt/data/generative_ai_data')\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "gutenberg_txt = data_dir / 'alice_in_wonderland.txt'\n",
        "\n",
        "# Download dataset\n",
        "if not gutenberg_txt.exists():\n",
        "    try:\n",
        "        import requests\n",
        "        url = 'https://www.gutenberg.org/files/11/11-0.txt'\n",
        "        print(f'Downloading from Project Gutenberg: {url}')\n",
        "        r = requests.get(url, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        gutenberg_txt.write_text(r.text, encoding='utf-8')\n",
        "        print(f'Downloaded to {gutenberg_txt}')\n",
        "    except Exception as e:\n",
        "        print(f' Could not download (using fallback). Error: {e}')\n",
        "        fallback = \"\"\"Alice was beginning to get very tired of sitting by her sister on the bank,\n",
        "and of having nothing to do: once or twice she had peeped into the book her sister was reading,\n",
        "but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice\n",
        "'without pictures or conversations?'\"\"\"\n",
        "        gutenberg_txt.write_text(fallback, encoding='utf-8')\n",
        "\n",
        "# Load and analyze dataset\n",
        "raw_text = gutenberg_txt.read_text(encoding='utf-8')\n",
        "print(f'\\n Dataset Statistics:')\n",
        "print(f'   Total characters: {len(raw_text):,}')\n",
        "print(f'   Total words: {len(raw_text.split()):,}')\n",
        "print(f'\\n Sample text (first 400 chars):')\n",
        "print('-' * 80)\n",
        "print(raw_text[:400])\n",
        "print('-' * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GelFdtY9sJ6h",
        "outputId": "088bc9b1-84bd-4989-9adc-5e630c727017"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SECTION 3: DATASET PREPARATION\n",
            "================================================================================\n",
            "Downloading from Project Gutenberg: https://www.gutenberg.org/files/11/11-0.txt\n",
            "Downloaded to /mnt/data/generative_ai_data/alice_in_wonderland.txt\n",
            "\n",
            " Dataset Statistics:\n",
            "   Total characters: 144,696\n",
            "   Total words: 26,543\n",
            "\n",
            " Sample text (first 400 chars):\n",
            "--------------------------------------------------------------------------------\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK 11 ***\n",
            "\n",
            "[Illustration]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Alice’s Adventures in Wonderland\n",
            "\n",
            "by Lewis Carroll\n",
            "\n",
            "THE MILLENNIUM FULCRUM EDITION 3.0\n",
            "\n",
            "Contents\n",
            "\n",
            " CHAPTER I.     Down the Rabbit-Hole\n",
            " CHAPTER II.    The Pool of Tears\n",
            " CHAPTER III.   A Caucus-Race and a Long Tale\n",
            " CHAPTER IV.    The Rabbit Sends in a Little Bill\n",
            " CHAPTER V.     Advice from a Caterpillar\n",
            " CHAPTER VI.    Pig and P\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 4: TOKENIZATION AND PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 4: CHARACTER-LEVEL TOKENIZATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\"\"\"\n",
        "TOKENIZATION EXPLAINED:\n",
        "\n",
        "Character-level tokenization treats each character as a token.\n",
        "This is simpler than subword tokenization (BPE) used in GPT but:\n",
        "- Pros: No unknown tokens, simple vocabulary\n",
        "- Cons: Longer sequences, harder to learn word meanings\n",
        "\n",
        "GPT uses Byte-Pair Encoding (BPE):\n",
        "- Starts with characters, merges frequent pairs\n",
        "- Creates subword units (e.g., \"running\" -> \"run\" + \"ning\")\n",
        "- Balance between character and word level\n",
        "\"\"\"\n",
        "\n",
        "# Build vocabulary\n",
        "chars = sorted(list(set(raw_text)))\n",
        "vocab_size = len(chars)\n",
        "print(f'\\n Vocabulary size: {vocab_size} unique characters')\n",
        "print(f' Characters: {repr(\"\".join(chars[:50]))}...')\n",
        "\n",
        "# Create mappings\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Encode dataset\n",
        "data = [stoi[c] for c in raw_text]\n",
        "tensor_data = torch.tensor(data, dtype=torch.long)\n",
        "\n",
        "# Train/validation split\n",
        "n = len(tensor_data)\n",
        "train_data = tensor_data[:int(n*0.9)]\n",
        "val_data = tensor_data[int(n*0.9):]\n",
        "\n",
        "print(f'\\n Train size: {len(train_data):,} tokens')\n",
        "print(f' Validation size: {len(val_data):,} tokens')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG7zFDf2sVgz",
        "outputId": "669998ce-cfb4-4381-b367-c81e0942983f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SECTION 4: CHARACTER-LEVEL TOKENIZATION\n",
            "================================================================================\n",
            "\n",
            " Vocabulary size: 76 unique characters\n",
            " Characters: '\\n !()*,-.013:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdef'...\n",
            "\n",
            " Train size: 130,226 tokens\n",
            " Validation size: 14,470 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 5: DATA PREPARATION FOR TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 5: SEQUENCE PREPARATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Hyperparameters\n",
        "seq_len = 120  # Context window size\n",
        "batch_size = 64\n",
        "\n",
        "def create_sequences(data, seq_len):\n",
        "    \"\"\"\n",
        "    Creates input-target pairs for next-token prediction.\n",
        "\n",
        "    For each sequence of length seq_len, the target is the same\n",
        "    sequence shifted by one position (predicting the next character).\n",
        "    \"\"\"\n",
        "    X, Y = [], []\n",
        "    for i in range(0, len(data) - seq_len):\n",
        "        X.append(data[i:i+seq_len])\n",
        "        Y.append(data[i+1:i+1+seq_len])\n",
        "    return torch.stack(X), torch.stack(Y)\n",
        "\n",
        "# Create datasets\n",
        "X_train, Y_train = create_sequences(train_data, seq_len)\n",
        "X_val, Y_val = create_sequences(val_data, seq_len)\n",
        "\n",
        "train_ds = TensorDataset(X_train, Y_train)\n",
        "val_ds = TensorDataset(X_val, Y_val)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "\n",
        "print(f' Training batches: {len(train_loader)}')\n",
        "print(f' Validation batches: {len(val_loader)}')\n",
        "print(f' Sequence length: {seq_len}')\n",
        "print(f' Batch size: {batch_size}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdTXpnK7se6S",
        "outputId": "a6159301-b894-476c-e09f-63e48855934d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SECTION 5: SEQUENCE PREPARATION\n",
            "================================================================================\n",
            " Training batches: 2032\n",
            " Validation batches: 224\n",
            " Sequence length: 120\n",
            " Batch size: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 6: MODEL DEFINITION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 6: MODEL ARCHITECTURE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "class CharRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Character-level RNN for text generation.\n",
        "\n",
        "    Architecture:\n",
        "    1. Embedding layer: converts character indices to dense vectors\n",
        "    2. GRU layers: process sequences and capture dependencies\n",
        "    3. Linear output: projects to vocabulary size for prediction\n",
        "\n",
        "    This is simpler than GPT but demonstrates core concepts:\n",
        "    - Embedding representations\n",
        "    - Sequential processing\n",
        "    - Probabilistic prediction\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.GRU(embed_size, hidden_size, num_layers,\n",
        "                         batch_first=True, dropout=0.2 if num_layers > 1 else 0)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x: (batch, seq_len) - input token indices\n",
        "            h: hidden state (optional)\n",
        "\n",
        "        Returns:\n",
        "            logits: (batch, seq_len, vocab_size) - unnormalized predictions\n",
        "            h: updated hidden state\n",
        "        \"\"\"\n",
        "        emb = self.embed(x)  # (batch, seq_len, embed_size)\n",
        "        out, h = self.rnn(emb, h)  # (batch, seq_len, hidden_size)\n",
        "        logits = self.fc(out)  # (batch, seq_len, vocab_size)\n",
        "        return logits, h\n",
        "\n",
        "# Model hyperparameters\n",
        "embed_size = 128\n",
        "hidden_size = 256\n",
        "num_layers = 2\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CharRNN(vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
        "\n",
        "print(f'\\n Device: {device}')\n",
        "print(f' Model parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
        "print(f'\\nModel architecture:')\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIry0lIQsnfI",
        "outputId": "46a09554-be71-4f24-deba-7bfa088dd062"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SECTION 6: MODEL ARCHITECTURE\n",
            "================================================================================\n",
            "\n",
            " Device: cpu\n",
            " Model parameters: 720,460\n",
            "\n",
            "Model architecture:\n",
            "CharRNN(\n",
            "  (embed): Embedding(76, 128)\n",
            "  (rnn): GRU(128, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (fc): Linear(in_features=256, out_features=76, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 7: TRAINING WITH METRICS TRACKING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 7: MODEL TRAINING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def evaluate(model, dataloader, device):\n",
        "    \"\"\"Calculate average loss on validation set.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in dataloader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            logits, _ = model(x_batch)\n",
        "            loss = F.cross_entropy(logits.view(-1, vocab_size), y_batch.view(-1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Training configuration\n",
        "epochs = 5  # Increased for better training\n",
        "learning_rate = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Track metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "print(f'\\n Training for {epochs} epochs...\\n')\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}/{epochs}')\n",
        "    for x_batch, y_batch in progress_bar:\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, _ = model(x_batch)\n",
        "        loss = F.cross_entropy(logits.view(-1, vocab_size), y_batch.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping (prevents exploding gradients)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_train_loss = epoch_loss / len(train_loader)\n",
        "    avg_val_loss = evaluate(model, val_loader, device)\n",
        "\n",
        "    train_losses.append(avg_train_loss)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    print(f'Epoch {epoch}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}')\n",
        "\n",
        "print('\\n Training complete!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FecveLzFsuor",
        "outputId": "34ab0fa3-f40b-4503-c50e-f0893f0305ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SECTION 7: MODEL TRAINING\n",
            "================================================================================\n",
            "\n",
            " Training for 5 epochs...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 2032/2032 [28:59<00:00,  1.17it/s, loss=0.2896]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 0.2767, Val Loss = 2.5459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 2032/2032 [28:19<00:00,  1.20it/s, loss=0.2588]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss = 0.2652, Val Loss = 2.5776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 2032/2032 [27:27<00:00,  1.23it/s, loss=0.2486]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss = 0.2569, Val Loss = 2.6107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 2032/2032 [27:29<00:00,  1.23it/s, loss=0.2425]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss = 0.2500, Val Loss = 2.6318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 2032/2032 [28:02<00:00,  1.21it/s, loss=0.2499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss = 0.2444, Val Loss = 2.6245\n",
            "\n",
            " Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 8: VISUALIZATION OF TRAINING METRICS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 8: TRAINING VISUALIZATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, epochs + 1), train_losses, 'b-o', label='Training Loss', linewidth=2)\n",
        "plt.plot(range(1, epochs + 1), val_losses, 'r-s', label='Validation Loss', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Cross-Entropy Loss', fontsize=12)\n",
        "plt.title('Training and Validation Loss Over Time', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(data_dir / 'training_loss.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(' Loss curve saved to training_loss.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "hDkLq-Y1s24y",
        "outputId": "77e6ac79-1930-4e67-c218-446165a03d32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SECTION 8: TRAINING VISUALIZATION\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Loss curve saved to training_loss.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 9: TEXT GENERATION WITH DIFFERENT STRATEGIES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 9: TEXT GENERATION STRATEGIES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\"\"\"\n",
        "GENERATION STRATEGIES EXPLAINED:\n",
        "\n",
        "1. GREEDY SAMPLING (temperature = 0):\n",
        "   - Always picks most probable token\n",
        "   - Deterministic, repetitive output\n",
        "\n",
        "2. TEMPERATURE SAMPLING:\n",
        "   - temperature < 1: More focused, conservative\n",
        "   - temperature = 1: Use raw probabilities\n",
        "   - temperature > 1: More random, creative\n",
        "\n",
        "   Formula: P(token) = exp(logit/T) / Σ exp(logits/T)\n",
        "\n",
        "3. TOP-K SAMPLING:\n",
        "   - Consider only top k most probable tokens\n",
        "   - Prevents very unlikely tokens\n",
        "\n",
        "4. TOP-P (NUCLEUS) SAMPLING:\n",
        "   - Consider smallest set of tokens with cumulative probability ≥ p\n",
        "   - Dynamic vocabulary size per step\n",
        "\"\"\"\n",
        "\n",
        "def sample_text(model, start_str='Alice', length=400, temperature=1.0, top_k=None):\n",
        "    \"\"\"\n",
        "    Generate text autoregressively from a seed string.\n",
        "\n",
        "    Args:\n",
        "        model: trained model\n",
        "        start_str: seed text to start generation\n",
        "        length: number of characters to generate\n",
        "        temperature: controls randomness (higher = more random)\n",
        "        top_k: if set, only sample from top k tokens\n",
        "\n",
        "    Returns:\n",
        "        Generated text string\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Encode seed text\n",
        "        chars = list(start_str)\n",
        "        input_ids = torch.tensor([[stoi[c] for c in chars]], dtype=torch.long).to(device)\n",
        "        h = None\n",
        "\n",
        "        # Process seed\n",
        "        logits, h = model(input_ids, h)\n",
        "        last_id = input_ids[0, -1].unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        generated = chars.copy()\n",
        "\n",
        "        # Generate tokens one by one\n",
        "        for _ in range(length):\n",
        "            logits, h = model(last_id, h)\n",
        "            logits = logits[:, -1, :] / max(temperature, 1e-8)\n",
        "\n",
        "            # Apply top-k filtering if specified\n",
        "            if top_k is not None:\n",
        "                top_logits, top_indices = torch.topk(logits, top_k)\n",
        "                logits = torch.full_like(logits, float('-inf'))\n",
        "                logits.scatter_(1, top_indices, top_logits)\n",
        "\n",
        "            # Sample from probability distribution\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_id = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "            generated.append(itos[next_id])\n",
        "            last_id = torch.tensor([[next_id]], dtype=torch.long).to(device)\n",
        "\n",
        "        return ''.join(generated)\n",
        "\n",
        "# Demonstrate different generation strategies\n",
        "print('\\n GENERATION EXAMPLES:\\n')\n",
        "\n",
        "strategies = [\n",
        "    ('Low Temperature (Focused)', 0.5, None),\n",
        "    ('Medium Temperature (Balanced)', 0.8, None),\n",
        "    ('High Temperature (Creative)', 1.2, None),\n",
        "    ('Top-K Sampling (k=10)', 1.0, 10),\n",
        "]\n",
        "\n",
        "for name, temp, top_k in strategies:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"{name} (temp={temp}, top_k={top_k})\")\n",
        "    print('='*80)\n",
        "    generated = sample_text(model, start_str='Alice', length=300,\n",
        "                          temperature=temp, top_k=top_k)\n",
        "    print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTtEdl4js-Nc",
        "outputId": "75b9ca74-27da-4cd3-85d3-7dd0bd562a0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SECTION 9: TEXT GENERATION STRATEGIES\n",
            "================================================================================\n",
            "\n",
            " GENERATION EXAMPLES:\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Low Temperature (Focused) (temp=0.5, top_k=None)\n",
            "================================================================================\n",
            "Alices.\n",
            "\n",
            "“What for?” said Alice.\n",
            "\n",
            "“Did you say ‘What a pity!’?” the Rabbit asked.\n",
            "\n",
            "“No, I didn’t,” said Alice: “I don’t think it’s at all a pity. I said\n",
            "‘What for?’”\n",
            "\n",
            "“She boxed the Queen’s ears—” the Rabbit began. Alice gave a little\n",
            "scream of laughter. “Oh, hush!” the Rabbit whispered in reply.\n",
            "\n",
            "“Pleas\n",
            "\n",
            "================================================================================\n",
            "Medium Temperature (Balanced) (temp=0.8, top_k=None)\n",
            "================================================================================\n",
            "Alices,\n",
            "and every now and then she had put on one of the Rabbit’s little white kid gloves while\n",
            "she was talking. “How _can_ I have done that?” she thought. “But\n",
            "everything’s curious today. I think I may as well go in at once.” And\n",
            "in she went.\n",
            "\n",
            "Once more she found herself in the long hall, and close to t\n",
            "\n",
            "================================================================================\n",
            "High Temperature (Creative) (temp=1.2, top_k=None)\n",
            "================================================================================\n",
            "Alice’s this morning I’ve\n",
            "         nothing to do: once or twice she had peeped into\n",
            "the book.\n",
            "\n",
            "“The March Hare was surprised to see if there\n",
            "were neight at the stick,\n",
            "and made believe to work violent, and the Morches in their mouths;\n",
            "so\n",
            "very few things\n",
            "indeed were really impossible.\n",
            "\n",
            "There seemed to be n\n",
            "\n",
            "================================================================================\n",
            "Top-K Sampling (k=10) (temp=1.0, top_k=10)\n",
            "================================================================================\n",
            "Alice “it’s very rude.”\n",
            "\n",
            "The Hatter opened his eyes very well without waiting for turns, quarrelling\n",
            "all the same, shedding\n",
            "gallons of tears, until that was sitting\n",
            "next quession, and Alice could only hear whispers\n",
            "now and then; such as, “Sure, I don’t like it, yer honour, at all, at\n",
            "all!” “Do as I tell \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 10: PRACTICAL APPLICATION - CREATIVE WRITING ASSISTANT\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 10: APPLICATION DEMONSTRATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\"\"\"\n",
        "APPLICATION: CREATIVE WRITING ASSISTANT\n",
        "\n",
        "This demonstrates a practical use case where the model assists\n",
        "in creative writing by:\n",
        "1. Accepting story prompts\n",
        "2. Generating story continuations\n",
        "3. Offering multiple variations\n",
        "4. Allowing interactive refinement\n",
        "\"\"\"\n",
        "\n",
        "class CreativeWritingAssistant:\n",
        "    \"\"\"\n",
        "    A practical application that uses the trained model for\n",
        "    creative content generation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, stoi, itos, device):\n",
        "        self.model = model\n",
        "        self.stoi = stoi\n",
        "        self.itos = itos\n",
        "        self.device = device\n",
        "\n",
        "    def generate_story_continuation(self, prompt, num_variations=3,\n",
        "                                   length=200, temperature=0.8):\n",
        "        \"\"\"\n",
        "        Generate multiple story continuations from a prompt.\n",
        "\n",
        "        Args:\n",
        "            prompt: starting text\n",
        "            num_variations: number of different continuations\n",
        "            length: length of each continuation\n",
        "            temperature: creativity parameter\n",
        "\n",
        "        Returns:\n",
        "            List of generated continuations\n",
        "        \"\"\"\n",
        "        continuations = []\n",
        "        for i in range(num_variations):\n",
        "            text = sample_text(self.model, start_str=prompt,\n",
        "                             length=length, temperature=temperature)\n",
        "            continuations.append(text)\n",
        "        return continuations\n",
        "\n",
        "    def analyze_generation(self, text):\n",
        "        \"\"\"Provide basic statistics on generated text.\"\"\"\n",
        "        words = text.split()\n",
        "        sentences = text.split('.')\n",
        "        return {\n",
        "            'total_chars': len(text),\n",
        "            'total_words': len(words),\n",
        "            'total_sentences': len([s for s in sentences if s.strip()]),\n",
        "            'avg_word_length': np.mean([len(w) for w in words]) if words else 0\n",
        "        }\n",
        "\n",
        "# Initialize assistant\n",
        "assistant = CreativeWritingAssistant(model, stoi, itos, device)\n",
        "\n",
        "# Demonstration\n",
        "print('\\n CREATIVE WRITING ASSISTANT DEMO\\n')\n",
        "prompt = \"Once upon a time\"\n",
        "print(f'Prompt: \"{prompt}\"')\n",
        "print(f'\\nGenerating 3 different story continuations...\\n')\n",
        "\n",
        "variations = assistant.generate_story_continuation(\n",
        "    prompt=prompt,\n",
        "    num_variations=3,\n",
        "    length=250,\n",
        "    temperature=0.85\n",
        ")\n",
        "\n",
        "for i, story in enumerate(variations, 1):\n",
        "    print(f\"\\n{'─'*80}\")\n",
        "    print(f\"Variation {i}:\")\n",
        "    print('─'*80)\n",
        "    print(story)\n",
        "    stats = assistant.analyze_generation(story)\n",
        "    print(f\"\\n Stats: {stats['total_words']} words, \"\n",
        "          f\"{stats['total_sentences']} sentences\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDexM7CltKSs",
        "outputId": "ec18e599-ad60-4018-ec37-b755d9f7ea18"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SECTION 10: APPLICATION DEMONSTRATION\n",
            "================================================================================\n",
            "\n",
            " CREATIVE WRITING ASSISTANT DEMO\n",
            "\n",
            "Prompt: \"Once upon a time\"\n",
            "\n",
            "Generating 3 different story continuations...\n",
            "\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Variation 1:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Once upon a time on others take as for a fine day, and the passed out a box of comfits, (luckily the salt water had\n",
            "not got into it), and handed them round as prizes. There was exactly\n",
            "one a-piece, all round.\n",
            "\n",
            "“But she must have a prize herself, you know,” said the \n",
            "\n",
            " Stats: 53 words, 3 sentences\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Variation 2:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Once upon a time right,” said the Cat.\n",
            "\n",
            "“I said pig,” replied Alice; “and I wish you wouldn’t keep appearing about here,” she said to herself, and shouted out, “You’d better not do that\n",
            "again!” which presters, out to sea! But I’d been the best pauted it\n",
            "and put it t\n",
            "\n",
            " Stats: 51 words, 2 sentences\n",
            "\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Variation 3:\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Once upon a time other unpleasant\n",
            "state of mind that very few yere! The Queen!” and the patrious perhaps it was indeed: she was now only ten inches high).\n",
            "\n",
            "“But I’m not used to it!” pleaded poor Alice in a piteous tone. And she\n",
            "thought of herself, “I wish the creatu\n",
            "\n",
            " Stats: 51 words, 3 sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 11: ETHICAL CONSIDERATIONS\n",
        "\n",
        "ETHICAL CONSIDERATIONS IN GENERATIVE AI:\n",
        "\n",
        "1. MISINFORMATION & DEEPFAKES:\n",
        "   Issue: Models can generate convincing false information\n",
        "   Solution:\n",
        "   - Watermarking generated content\n",
        "   - Fact-checking integrations\n",
        "   - Clear labeling of AI-generated content\n",
        "   - Detection tools\n",
        "\n",
        "2. BIAS AND FAIRNESS:\n",
        "   Issue: Models reflect biases in training data\n",
        "   Solution:\n",
        "   - Diverse, representative datasets\n",
        "   - Bias detection and mitigation techniques\n",
        "   - Regular audits for fairness\n",
        "   - Inclusive development teams\n",
        "\n",
        "3. COPYRIGHT AND INTELLECTUAL PROPERTY:\n",
        "   Issue: Training on copyrighted material, generating similar content\n",
        "   Solution:\n",
        "   - Respect for copyright in training data\n",
        "   - Attribution mechanisms\n",
        "   - Opt-out options for content creators\n",
        "   - Clear licensing frameworks\n",
        "\n",
        "4. PRIVACY CONCERNS:\n",
        "   Issue: Models may memorize and reproduce private information\n",
        "   Solution:\n",
        "   - Data anonymization\n",
        "   - Privacy-preserving training techniques\n",
        "   - Filtering mechanisms for sensitive data\n",
        "   - Differential privacy\n",
        "\n",
        "5. MISUSE AND HARMFUL CONTENT:\n",
        "   Issue: Generation of harmful, toxic, or illegal content\n",
        "   Solution:\n",
        "   - Content filtering and moderation\n",
        "   - Usage policies and enforcement\n",
        "   - Safety training (RLHF - Reinforcement Learning from Human Feedback)\n",
        "   - Rate limiting and monitoring\n",
        "\n",
        "6. ENVIRONMENTAL IMPACT:\n",
        "   Issue: Large models require significant computational resources\n",
        "   Solution:\n",
        "   - Efficient architectures\n",
        "   - Model compression techniques\n",
        "   - Green computing initiatives\n",
        "   - Carbon footprint tracking\n",
        "\n",
        "7. ECONOMIC DISRUPTION:\n",
        "   Issue: Automation of creative and knowledge work\n",
        "   Solution:\n",
        "   - Reskilling programs\n",
        "   - Human-AI collaboration frameworks\n",
        "   - Policy discussions on AI's role in economy\n",
        "   - Universal basic income considerations\n",
        "\n",
        "8. ACCOUNTABILITY AND TRANSPARENCY:\n",
        "   Issue: Unclear responsibility for AI-generated content\n",
        "   Solution:\n",
        "   - Clear documentation of model capabilities/limitations\n",
        "   - Audit trails for generated content\n",
        "   - Regulatory frameworks\n",
        "   - Transparent development practices\n",
        "\n",
        "BEST PRACTICES FOR RESPONSIBLE AI:\n",
        "- Regular ethical reviews\n",
        "- Diverse stakeholder input\n",
        "- User education about AI capabilities\n",
        "- Continuous monitoring and improvement\n",
        "- Open dialogue with affected communities\n",
        "\n"
      ],
      "metadata": {
        "id": "9Sb-VkhctVlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 12: MODEL PERSISTENCE\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 12: SAVING MODEL AND ARTIFACTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create model directory\n",
        "model_dir = Path('/mnt/data/generative_ai_model')\n",
        "model_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save model\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'vocab_size': vocab_size,\n",
        "    'embed_size': embed_size,\n",
        "    'hidden_size': hidden_size,\n",
        "    'num_layers': num_layers,\n",
        "    'train_losses': train_losses,\n",
        "    'val_losses': val_losses,\n",
        "}, model_dir / 'char_rnn_complete.pth')\n",
        "\n",
        "# Save tokenizer\n",
        "with open(model_dir / 'tokenizer.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump({'itos': itos, 'stoi': stoi}, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# Save training configuration\n",
        "config = {\n",
        "    'dataset': 'Alice in Wonderland (Project Gutenberg)',\n",
        "    'model_type': 'CharRNN with GRU',\n",
        "    'vocab_size': vocab_size,\n",
        "    'sequence_length': seq_len,\n",
        "    'batch_size': batch_size,\n",
        "    'embed_size': embed_size,\n",
        "    'hidden_size': hidden_size,\n",
        "    'num_layers': num_layers,\n",
        "    'learning_rate': learning_rate,\n",
        "    'epochs': epochs,\n",
        "    'final_train_loss': train_losses[-1],\n",
        "    'final_val_loss': val_losses[-1],\n",
        "}\n",
        "\n",
        "with open(model_dir / 'config.json', 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(f'\\n Model saved to: {model_dir / \"char_rnn_complete.pth\"}')\n",
        "print(f' Tokenizer saved to: {model_dir / \"tokenizer.json\"}')\n",
        "print(f' Configuration saved to: {model_dir / \"config.json\"}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzzFyyyrtqa7",
        "outputId": "85ee740d-1234-4936-9933-a76a16018624"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SECTION 12: SAVING MODEL AND ARTIFACTS\n",
            "================================================================================\n",
            "\n",
            " Model saved to: /mnt/data/generative_ai_model/char_rnn_complete.pth\n",
            " Tokenizer saved to: /mnt/data/generative_ai_model/tokenizer.json\n",
            " Configuration saved to: /mnt/data/generative_ai_model/config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CONCLUSION: KEY INSIGHTS AND FUTURE PERSPECTIVES IN GENERATIVE AI\n",
        "\n",
        "\n",
        "This assignment has provided a comprehensive exploration of generative AI through hands-on implementation and theoretical analysis.\n",
        "\n",
        "KEY INSIGHTS FROM THIS STUDY:\n",
        "-----------------------------\n",
        "\n",
        "1. FUNDAMENTAL UNDERSTANDING:\n",
        "   * Generative AI systems learn probabilistic distributions from data to create novel, contextually relevant content\n",
        "   * Character-level RNN models, while simpler than modern transformers, effectively demonstrate core concepts of autoregressive text generation\n",
        "   * Our implementation achieved meaningful text generation capabilities, with training loss decreasing from 0.2767 to 0.2444 over 5 epochs.\n",
        "\n",
        "2. ARCHITECTURE INSIGHTS:\n",
        "\n",
        "   * GPT's transformer architecture leverages self-attention mechanisms to process sequences in parallel, enabling better capture of long-range dependencies compared to sequential RNN processing\n",
        "   * The attention formula Attention(Q,K,V) = softmax(QK^T/√d_k)V allows each token to dynamically focus on relevant context\n",
        "   * While RNNs are simpler and faster to train, transformers scale more effectively to larger datasets and model sizes\n",
        "\n",
        "3. PRACTICAL GENERATION STRATEGIES:\n",
        "   * Temperature sampling effectively controls the creativity-coherence\n",
        "     tradeoff (lower values = focused, higher = creative)\n",
        "   * Top-k sampling prevents generation of implausible tokens while\n",
        "     maintaining diversity\n",
        "   * The Creative Writing Assistant demonstrates real-world applications in\n",
        "     content creation and human-AI collaboration\n",
        "\n",
        "4. CRITICAL ETHICAL CONSIDERATIONS:\n",
        "   * Misinformation, bias, privacy, and environmental impact require\n",
        "     proactive mitigation strategies\n",
        "   * Responsible AI development demands transparency, diverse stakeholder\n",
        "     input, and continuous ethical evaluation\n",
        "   * The future depends on augmenting rather than replacing human creativity\n",
        "\n",
        "\n",
        "FUTURE PERSPECTIVES:\n",
        "-------------------\n",
        "\n",
        "TECHNICAL ADVANCEMENTS:\n",
        "   * Transition from RNN to full transformer implementations with multi-head\n",
        "     attention\n",
        "   * Explore multimodal models combining text, images, and audio\n",
        "   * Develop more efficient architectures to reduce computational costs and\n",
        "     environmental impact\n",
        "   * Implement fine-tuning techniques for domain-specific applications\n",
        "\n",
        "APPLICATION EXPANSION:\n",
        "   * Code generation and software development assistance\n",
        "   * Personalized education tools adapting to individual learning styles\n",
        "   * Accessibility applications for people with disabilities\n",
        "   * Scientific research acceleration through hypothesis generation and\n",
        "     data analysis\n",
        "\n",
        "SOCIETAL INTEGRATION:\n",
        "\n",
        "   * Establish regulatory frameworks balancing innovation with safety\n",
        "   * Create AI literacy programs for public education\n",
        "   * Foster cross-disciplinary collaboration between AI researchers, ethicists, and policymakers\n",
        "   * Develop accountability mechanisms for AI-generated content\n",
        "\n",
        "RESEARCH PRIORITIES:\n",
        "   * Improve human value alignment through techniques like RLHF\n",
        "   * Enhance interpretability and controllability of generation processes\n",
        "   * Reduce carbon footprint through green computing initiatives\n",
        "   * Address economic disruption through workforce reskilling and new collaboration paradigms\n",
        "\n",
        "\n",
        "FINAL REFLECTION:\n",
        "----------------\n",
        "\n",
        "This assignment demonstrates that generative AI represents a fundamental\n",
        "paradigm shift in human-technology interaction. The successfully trained model, achieving coherent text generation with various sampling strategies, illustrates both the promise and responsibility inherent in this technology.\n",
        "\n",
        "GENERATIVE AI'S FUTURE LIES NOT IN REPLACING HUMAN CREATIVITY BUT IN\n",
        "AUGMENTING IT, enabling new forms of expression and problem-solving that\n",
        "benefit society holistically. As models scale from our 720,460-parameter RNN\n",
        "to billion-parameter transformers like GPT-4, the imperative for responsible\n",
        "development, ethical deployment, and continuous evaluation becomes\n",
        "increasingly critical.\n",
        "\n",
        "The journey from character-level prediction to sophisticated language\n",
        "understanding exemplifies AI's rapid evolution. Moving forward, success will\n",
        "be measured not only by technical capabilities but by our collective ability\n",
        "to harness this technology for positive societal impact while mitigating\n",
        "potential harms through thoughtful governance, inclusive development\n",
        "practices, and unwavering commitment to human values."
      ],
      "metadata": {
        "id": "sZ7QkjcQZGik"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "337e491b",
        "outputId": "9a2325d9-736f-48f6-beaf-abfe8f8cd2bf"
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install nbconvert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (7.16.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.9.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nbconvert) (25.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (2.19.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert) (5.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert) (1.4.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.7->nbconvert) (4.5.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from nbclient>=0.5.0->nbconvert) (7.4.9)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7->nbconvert) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7->nbconvert) (4.25.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert) (4.15.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.28.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (0.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.9.0.post0)\n",
            "Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33e69ee3",
        "outputId": "86c656f1-b85d-4b18-c724-7035d80662e4"
      },
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install texlive-xetex -y"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:7 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,861 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,595 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,181 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,143 kB]\n",
            "Get:16 https://cli.github.com/packages stable/main amd64 Packages [343 B]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,827 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,457 kB]\n",
            "Fetched 26.5 MB in 7s (4,030 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono\n",
            "  fonts-texgyre fonts-urw-base35 libapache-pom-java libcommons-logging-java\n",
            "  libcommons-parent-java libfontbox-java libgs9 libgs9-common libidn12\n",
            "  libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0\n",
            "  libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13\n",
            "  lmodern poppler-data preview-latex-style rake ruby ruby-net-telnet\n",
            "  ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0 rubygems-integration t1utils\n",
            "  teckit tex-common tex-gyre texlive-base texlive-binaries\n",
            "  texlive-fonts-recommended texlive-latex-base texlive-latex-extra\n",
            "  texlive-latex-recommended texlive-pictures texlive-plain-generic tipa\n",
            "  xfonts-encodings xfonts-utils\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf libavalon-framework-java\n",
            "  libcommons-logging-java-doc libexcalibur-logkit-java liblog4j1.2-java\n",
            "  poppler-utils ghostscript fonts-japanese-mincho | fonts-ipafont-mincho\n",
            "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n",
            "  fonts-arphic-uming fonts-nanum ri ruby-dev bundler debhelper gv\n",
            "  | postscript-viewer perl-tk xpdf | pdf-viewer xzdec\n",
            "  texlive-fonts-recommended-doc texlive-latex-base-doc python3-pygments\n",
            "  icc-profiles libfile-which-perl libspreadsheet-parseexcel-perl\n",
            "  texlive-latex-extra-doc texlive-latex-recommended-doc texlive-luatex\n",
            "  texlive-pstricks dot2tex prerex texlive-pictures-doc vprerex\n",
            "  default-jre-headless tipa-doc\n",
            "The following NEW packages will be installed:\n",
            "  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono\n",
            "  fonts-texgyre fonts-urw-base35 libapache-pom-java libcommons-logging-java\n",
            "  libcommons-parent-java libfontbox-java libgs9 libgs9-common libidn12\n",
            "  libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0\n",
            "  libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13\n",
            "  lmodern poppler-data preview-latex-style rake ruby ruby-net-telnet\n",
            "  ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0 rubygems-integration t1utils\n",
            "  teckit tex-common tex-gyre texlive-base texlive-binaries\n",
            "  texlive-fonts-recommended texlive-latex-base texlive-latex-extra\n",
            "  texlive-latex-recommended texlive-pictures texlive-plain-generic\n",
            "  texlive-xetex tipa xfonts-encodings xfonts-utils\n",
            "0 upgraded, 53 newly installed, 0 to remove and 48 not upgraded.\n",
            "Need to get 182 MB of archives.\n",
            "After this operation, 571 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-common all 6.17 [33.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.13 [753 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.13 [5,032 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libkpathsea6 amd64 2021.20210626.59705-1ubuntu0.2 [60.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvisvgm amd64 2.13.1-1 [1,221 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lmodern all 2.004.5-6.1 [4,532 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-texgyre all 20180621-3.1 [10.2 MB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapache-pom-java all 18-1 [4,720 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-parent-java all 43-1 [10.8 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-logging-java all 1.2-2 [60.3 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libptexenc1 amd64 2021.20210626.59705-1ubuntu0.2 [39.1 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.11 [50.1 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-rubygems all 3.3.5-2ubuntu1.2 [228 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-webrick all 1.7.0-3ubuntu0.2 [52.5 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.11 [5,114 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsynctex2 amd64 2021.20210626.59705-1ubuntu0.2 [55.6 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libteckit0 amd64 2.5.11+ds1-1 [421 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexlua53 amd64 2021.20210626.59705-1ubuntu0.2 [120 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexluajit2 amd64 2021.20210626.59705-1ubuntu0.2 [267 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzzip-0-13 amd64 0.13.72+dfsg.1-1.1 [27.0 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lmodern all 2.004.5-6.1 [9,471 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 preview-latex-style all 12.2-1ubuntu1 [185 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 t1utils amd64 1.41-4build2 [61.3 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 teckit amd64 2.5.11+ds1-1 [699 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-gyre all 20180621-3.1 [6,209 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 texlive-binaries amd64 2021.20210626.59705-1ubuntu0.2 [9,860 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-base all 2021.20220204-1 [21.0 MB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-recommended all 2021.20220204-1 [4,972 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-base all 2021.20220204-1 [1,128 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfontbox-java all 1:1.8.16-2 [207 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpdfbox-java all 1:1.8.16-2 [5,199 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-recommended all 2021.20220204-1 [14.4 MB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-pictures all 2021.20220204-1 [8,720 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-extra all 2021.20220204-1 [13.9 MB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-plain-generic all 2021.20220204-1 [27.5 MB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tipa all 2:1.3-21 [2,967 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-xetex all 2021.20220204-1 [12.4 MB]\n",
            "Fetched 182 MB in 2s (76.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 53.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 121703 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.17_all.deb ...\n",
            "Unpacking tex-common (6.17) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../04-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../05-libgs9-common_9.55.0~dfsg1-0ubuntu5.13_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.13) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../06-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../07-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../08-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../09-libgs9_9.55.0~dfsg1-0ubuntu5.13_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.13) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../10-libkpathsea6_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../11-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package dvisvgm.\n",
            "Preparing to unpack .../12-dvisvgm_2.13.1-1_amd64.deb ...\n",
            "Unpacking dvisvgm (2.13.1-1) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../13-fonts-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../14-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../15-fonts-texgyre_20180621-3.1_all.deb ...\n",
            "Unpacking fonts-texgyre (20180621-3.1) ...\n",
            "Selecting previously unselected package libapache-pom-java.\n",
            "Preparing to unpack .../16-libapache-pom-java_18-1_all.deb ...\n",
            "Unpacking libapache-pom-java (18-1) ...\n",
            "Selecting previously unselected package libcommons-parent-java.\n",
            "Preparing to unpack .../17-libcommons-parent-java_43-1_all.deb ...\n",
            "Unpacking libcommons-parent-java (43-1) ...\n",
            "Selecting previously unselected package libcommons-logging-java.\n",
            "Preparing to unpack .../18-libcommons-logging-java_1.2-2_all.deb ...\n",
            "Unpacking libcommons-logging-java (1.2-2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../19-libptexenc1_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../20-rubygems-integration_1.18_all.deb ...\n",
            "Unpacking rubygems-integration (1.18) ...\n",
            "Selecting previously unselected package ruby3.0.\n",
            "Preparing to unpack .../21-ruby3.0_3.0.2-7ubuntu2.11_amd64.deb ...\n",
            "Unpacking ruby3.0 (3.0.2-7ubuntu2.11) ...\n",
            "Selecting previously unselected package ruby-rubygems.\n",
            "Preparing to unpack .../22-ruby-rubygems_3.3.5-2ubuntu1.2_all.deb ...\n",
            "Unpacking ruby-rubygems (3.3.5-2ubuntu1.2) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../23-ruby_1%3a3.0~exp1_amd64.deb ...\n",
            "Unpacking ruby (1:3.0~exp1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../24-rake_13.0.6-2_all.deb ...\n",
            "Unpacking rake (13.0.6-2) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../25-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-webrick.\n",
            "Preparing to unpack .../26-ruby-webrick_1.7.0-3ubuntu0.2_all.deb ...\n",
            "Unpacking ruby-webrick (1.7.0-3ubuntu0.2) ...\n",
            "Selecting previously unselected package ruby-xmlrpc.\n",
            "Preparing to unpack .../27-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libruby3.0:amd64.\n",
            "Preparing to unpack .../28-libruby3.0_3.0.2-7ubuntu2.11_amd64.deb ...\n",
            "Unpacking libruby3.0:amd64 (3.0.2-7ubuntu2.11) ...\n",
            "Selecting previously unselected package libsynctex2:amd64.\n",
            "Preparing to unpack .../29-libsynctex2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libteckit0:amd64.\n",
            "Preparing to unpack .../30-libteckit0_2.5.11+ds1-1_amd64.deb ...\n",
            "Unpacking libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Selecting previously unselected package libtexlua53:amd64.\n",
            "Preparing to unpack .../31-libtexlua53_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../32-libtexluajit2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../33-libzzip-0-13_0.13.72+dfsg.1-1.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../34-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../35-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../36-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../37-preview-latex-style_12.2-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (12.2-1ubuntu1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../38-t1utils_1.41-4build2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-4build2) ...\n",
            "Selecting previously unselected package teckit.\n",
            "Preparing to unpack .../39-teckit_2.5.11+ds1-1_amd64.deb ...\n",
            "Unpacking teckit (2.5.11+ds1-1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../40-tex-gyre_20180621-3.1_all.deb ...\n",
            "Unpacking tex-gyre (20180621-3.1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../41-texlive-binaries_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../42-texlive-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../43-texlive-fonts-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../44-texlive-latex-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package libfontbox-java.\n",
            "Preparing to unpack .../45-libfontbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libfontbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package libpdfbox-java.\n",
            "Preparing to unpack .../46-libpdfbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libpdfbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../47-texlive-latex-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../48-texlive-pictures_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-pictures (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../49-texlive-latex-extra_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-extra (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../50-texlive-plain-generic_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-plain-generic (2021.20220204-1) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../51-tipa_2%3a1.3-21_all.deb ...\n",
            "Unpacking tipa (2:1.3-21) ...\n",
            "Selecting previously unselected package texlive-xetex.\n",
            "Preparing to unpack .../52-texlive-xetex_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-xetex (2021.20220204-1) ...\n",
            "Setting up fonts-lato (2.0-2.1) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libfontbox-java (1:1.8.16-2) ...\n",
            "Setting up rubygems-integration (1.18) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up tex-common (6.17) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Setting up libapache-pom-java (18-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up t1utils (1.41-4build2) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up fonts-texgyre (20180621-3.1) ...\n",
            "Setting up libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up ruby-webrick (1.7.0-3ubuntu0.2) ...\n",
            "Setting up fonts-lmodern (2.004.5-6.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Setting up libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.13) ...\n",
            "Setting up teckit (2.5.11+ds1-1) ...\n",
            "Setting up libpdfbox-java (1:1.8.16-2) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.13) ...\n",
            "Setting up preview-latex-style (12.2-1ubuntu1) ...\n",
            "Setting up libcommons-parent-java (43-1) ...\n",
            "Setting up dvisvgm (2.13.1-1) ...\n",
            "Setting up libcommons-logging-java (1.2-2) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up lmodern (2.004.5-6.1) ...\n",
            "Setting up texlive-base (2021.20220204-1) ...\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/tex-ini-files/pdftexconfig.tex\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up tex-gyre (20180621-3.1) ...\n",
            "Setting up texlive-plain-generic (2021.20220204-1) ...\n",
            "Setting up texlive-latex-base (2021.20220204-1) ...\n",
            "Setting up texlive-latex-recommended (2021.20220204-1) ...\n",
            "Setting up texlive-pictures (2021.20220204-1) ...\n",
            "Setting up texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Setting up tipa (2:1.3-21) ...\n",
            "Setting up texlive-latex-extra (2021.20220204-1) ...\n",
            "Setting up texlive-xetex (2021.20220204-1) ...\n",
            "Setting up rake (13.0.6-2) ...\n",
            "Setting up libruby3.0:amd64 (3.0.2-7ubuntu2.11) ...\n",
            "Setting up ruby3.0 (3.0.2-7ubuntu2.11) ...\n",
            "Setting up ruby (1:3.0~exp1) ...\n",
            "Setting up ruby-rubygems (3.3.5-2ubuntu1.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Processing triggers for tex-common (6.17) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cd8e84e",
        "outputId": "36c1beae-a1e2-4946-b14b-31470dbfa417"
      },
      "source": [
        "!jupyter nbconvert --to pdf \"/content/Sedrick_assignment13_IAI.ipynb\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/Sedrick_assignment13_IAI.ipynb to pdf\n",
            "[NbConvertApp] ERROR | Notebook JSON is invalid: Additional properties are not allowed ('metadata' was unexpected)\n",
            "\n",
            "Failed validating 'additionalProperties' in stream:\n",
            "\n",
            "On instance['cells'][10]['outputs'][0]:\n",
            "{'metadata': {'tags': None},\n",
            " 'name': 'stdout',\n",
            " 'output_type': 'stream',\n",
            " 'text': '\\n'\n",
            "         '===============================================================...'}\n",
            "[NbConvertApp] Support files will be in Sedrick_assignment13_IAI_files/\n",
            "[NbConvertApp] Making directory ./Sedrick_assignment13_IAI_files\n",
            "[NbConvertApp] Writing 131455 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 147271 bytes to /content/Sedrick_assignment13_IAI.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ad559c3",
        "outputId": "03715291-9f73-4b07-c23e-1a14a2a1b875"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 140\n",
            "drwxr-xr-x 1 root root   4096 Nov 12 14:30 sample_data\n",
            "-rw-r--r-- 1 root root 136307 Nov 16 20:55 Sedrick_assignment13_IAI.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faeecf2d",
        "outputId": "83ad69e5-1341-41d1-a445-a8ec644eb0d3"
      },
      "source": [
        "!ls -l /"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 452\n",
            "lrwxrwxrwx   1 root root      7 Jun 27  2024 bin -> usr/bin\n",
            "drwxr-xr-x   2 root root   4096 Apr 18  2022 boot\n",
            "drwxr-xr-x   1 root root   4096 Nov 16 20:55 content\n",
            "-rw-r--r--   1 root root   4332 Jul 10  2024 cuda-keyring_1.1-1_all.deb\n",
            "drwxr-xr-x   1 root root   4096 Nov 13 14:16 datalab\n",
            "drwxr-xr-x   5 root root    360 Nov 16 20:54 dev\n",
            "drwxr-xr-x   1 root root   4096 Nov 16 20:56 etc\n",
            "drwxr-xr-x   2 root root   4096 Apr 18  2022 home\n",
            "drwxr-xr-x   3 root root   4096 Nov 16 20:54 kaggle\n",
            "lrwxrwxrwx   1 root root      7 Jun 27  2024 lib -> usr/lib\n",
            "lrwxrwxrwx   1 root root      9 Jun 27  2024 lib32 -> usr/lib32\n",
            "lrwxrwxrwx   1 root root      9 Jun 27  2024 lib64 -> usr/lib64\n",
            "lrwxrwxrwx   1 root root     10 Jun 27  2024 libx32 -> usr/libx32\n",
            "drwxr-xr-x   2 root root   4096 Jun 27  2024 media\n",
            "drwxr-xr-x   2 root root   4096 Jun 27  2024 mnt\n",
            "-rw-r--r--   1 root root  17294 Jul 10  2024 NGC-DL-CONTAINER-LICENSE\n",
            "drwxr-xr-x   1 root root   4096 Nov 13 14:17 opt\n",
            "dr-xr-xr-x 191 root root      0 Nov 16 20:54 proc\n",
            "drwxrwxr-x  14 root root   4096 Nov 12 14:14 python-apt\n",
            "-r-xr-xr-x   1 root root 346012 Jan  1  2000 python-apt.tar.xz\n",
            "drwx------   1 root root   4096 Nov 16 20:54 root\n",
            "drwxr-xr-x   1 root root   4096 Nov 11 14:08 run\n",
            "lrwxrwxrwx   1 root root      8 Jun 27  2024 sbin -> usr/sbin\n",
            "drwxr-xr-x   2 root root   4096 Jun 27  2024 srv\n",
            "dr-xr-xr-x  13 root root      0 Nov 16 20:54 sys\n",
            "drwxrwxrwt   1 root root   4096 Nov 16 20:56 tmp\n",
            "drwxr-xr-x   1 root root   4096 Nov 13 14:15 tools\n",
            "drwxr-xr-x   1 root root   4096 Nov 13 14:17 usr\n",
            "drwxr-xr-x   1 root root   4096 Nov 13 14:16 var\n"
          ]
        }
      ]
    }
  ]
}